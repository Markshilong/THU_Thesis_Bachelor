% !TeX root = ../thuthesis-example.tex

\chapter{评价指标与实验结果}

本章首先介绍本文所实现的多摄像头多目标行人位置估计算法中所采用的实验评价指标，然后详细阐述实验过程和实验的环境、参数。最后，将实验结果与目前业界最新算法进行比较，并提出未来可能的改进建议。

\section{评价指标}

精确率(Precision)和召回率(Recall)是广泛用于信息检索和统计学分类领域的两个度量值，用来评价结果的质量。因此，本文采用了精确率、召回率来衡量最终位置估计效果。然而，由于在大规模数据集合中，精确率和召回率两个指标往往是相互制约的，因此，本文还采用了F分数(F-score)来综合权衡精确率和召回率。即，本文共使用了精确率、召回率和F分数三个评价指标来衡量最终的位置估计效果。

为了得到上述三个评价指标，首先需要得到实验结果的混淆矩阵(Confusion Matrix)。混淆矩阵也称误差矩阵，是表示精度评价的一种标准格式，在本文中为两行两列的矩阵形式。其主要参数有四个，即真阳性(True Positives, TP)、真阴性(True Negatives, TN)、假阳性(False Positives, FP)、假阴性(False Negatives, FN)。在本文实验中，TP集合为与实际位置相符的预测点；TN集合应为预测点之外的点中排除实际位置的点，由于计算上述三个评价指标并没有用到TN集合，故被忽略；FP集合为预测点中没有命中实际位置的点；FN集合为没有被预测到的实际位置点。在本实验中，预测点与实际位置命中的判定半径为$r=0.5m$，即若预测点与实际点距离相聚小于50cm即判定为成功估计了行人的位置。

上文提到，计算混淆矩阵的参数时，需要判定预测点与实际位置点是否对应，从而判定是否正确预测。现在，我们得到了对行人位置在地面上的最终预测点，同时，我们有行人地面实际位置的标注，那么就需要将这些预测点和实际标注一一匹配起来，从而可以计算预测点与实际点之间的距离，以判断是否预测成功。解决上述匹配问题的方法可以抽象为图论中寻找最大匹配的算法，在本文中，上述问题抽象为在二分图中寻找最大匹配。因此，我们实现了匈牙利算法(Hungarian Algorithm)来解决这一问题。匈牙利算法利用深度优先搜索来不断寻找增广路。它从每个未匹配的实际地面点开始，如果直接找到了预测点中未匹配的点，则直接返回此匹配路径；若找到预测点已匹配的点，那么从该点匹配的点出发继续深度优先搜索未匹配点。

得到混淆矩阵后，可以计算上述三个评价指标。
\begin{itemize}
    \item 精确率(Precision) 精确率是针对预测结果而言的，它表示的是预测点中有多少是预测正确的。精确率显示了模型预测点的精确性，可由下式计算：
        \begin{equation*}
            \text{Precision}=\frac{\text{TP}}{\text{TP}+\text{FP}}
        \end{equation*}
    \item 召回率(Recall) 召回率是针对原来的样本而言的，它表示的是实际位置点中有多少被预测命中了。召回率显示了模型是否能够估计出视野中更多行人的实际位置，其可由下式计算：
    \begin{equation*}
        \text{Recall}=\frac{\text{TP}}{\text{TP}+\text{FN}}
    \end{equation*}
    \item F分数(F-score) 精确率和召回率指标有时候会出现矛盾的情况，这样就需要综合考虑二者，最常见的方法就是利用F分数，即精确率和召回率的加权调和平均：
    \begin{equation*}
        \text{F-score}=(1+\beta^2)\cdot \frac{\text{Precision} \cdot \text{Recall}}{\beta^2 \cdot \text{Precision} \cdot \text{Recall}}
    \end{equation*}
    本文中令$\beta=1$，即实际上使用F1-score。
\end{itemize}

\section{实验设置和结果分析}

我们利用了表~\ref{parameter_table}中的超参数进行层次聚类的数据融合，之后可以初步得到行人位置估计结果，这些实验结果与深度学习方法的比较如表~\ref{experiments}所示。

在深度学习方法中，主要在WildTrack数据集上进行实验。其中，作为训练集的是从WildTrack数据集提供的七个摄像头视频提取到的视频帧，每个摄像头共有11558张图片，其中真值由官方提供的400张图片真值插值得到；作为测试集的是WildTrack数据集提供的每个摄像头400张的去畸变图，提供了真值标注。实现的ResUNet和ResUNet++网络均基于PyTorch，部署在NVIDIA RTX 3090 GPU进行训练，系统版本为Ubuntu 18.04，提供CUDA 11.3支持。在训练的过程中，输入热图和输出预测图的尺寸均为$224\times 672$，输入网络时采用的Batch Size为4，使用Adam优化器进行调优。同时，为了避免网络难以收敛到最优状态，初始学习率设置为1e-3，每20个训练周期(epoch)学习率衰减为原来的0.1倍，一共训练120个周期。

最后，将深度学习方法中ResUNet和ResUNet++网络的实验结果与目前领域内几个深度学习方法的比较如下表~\ref{experiments}所示。
\begin{table}
    \centering
    \caption{层次聚类方法、ResUNet和ResUNet++与其他方法实验效果比较}
    \begin{tabular}{llll}
        \toprule
        方法 & 精确率  & 召回率 & F分数                       \\
        \midrule
        Deep-Occlusion\cite{baque2017deep} & 95\% & 80\% & 86\%                  \\
        Generalized Mutiview Detection\cite{2021Generalizable} & 93\% & 94\% & 93\%  \\
        Hierarchical Clustering & 62\% & 87\% & 72\%         \\
        ResUNet & 70\% & 92\% & 79\%                         \\
        ResUNet++ & 82\% & 98\% & 89\%                      \\
        \bottomrule
    \end{tabular}
    \label{experiments}
\end{table}

由表~\ref{experiments}可以看出，ResUNet++网络结构效果比ResUNet效果好很多，而没有使用神经网络的层次聚类融合方法效果最差。同时，也可以发现，ResUNet++在多摄像头多目标行人位置估计领域，在未使用行人重识别和时序信息的情况下，达到了接近目前业界领先算法的效果。

\section{本章小结}

本章中主要介绍了实验的评价指标、实验设置细节和具体实验结果的分析。实验的评价指标主要使用了精确率、召回率和F分数三个指标来衡量算法位置估计的效果，实验设置上，对数据集进行扩充以增加训练量，同时利用学习率衰减的训练策略，提升了训练效果。在实验结果方面，仅仅使用层次聚类来得到行人的位置估计的算法效果并不好，而在层次聚类的基础上利用ResUNet和ResUNet++的深度学习网络可以达到较好的效果。此外，所实现的ResUNet++在ResUNet基础上改进而来，达到了接近目前最优算法的性能。